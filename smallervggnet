from keras.models import Sequential
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dropout
from keras.layers.core import Dense
from keras import backend as K
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
import astropy
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


class SmallerVGGnet:
    @staticmethod
    def build(width,height,depth,classes):
        #initialize the model along with the shape
        model=Sequential()
        # inputShape=(height,width.depth,classes)
        chanDim=-1
        #
        # if K.image_data_format()=='channels_first':
        #      inputshape=(depth,height,width,classes)
        #      chanDim=1
        #CONV=>RELU=>POOL
        model.add(Conv2D(128,(3,3),padding='same',input_shape=(width,height,depth)))
        model.add(Activation('relu'))
        model.add(BatchNormalization(axis=chanDim))
        model.add(MaxPooling2D(pool_size=(3,3)))
        model.add(Dropout(0.25))
     #   (CONV=>RELU)*2=>POOL
        model.add(Conv2D(64,(3,3),padding='same',input_shape=(width,height,depth)))
        model.add(Activation('relu'))
        model.add(BatchNormalization(axis=chanDim))
        model.add(Conv2D(64,(3,3),padding='same',input_shape=(width,height,depth)))
        model.add(Activation('relu'))
        model.add(BatchNormalization(axis=chanDim))
        model.add(MaxPooling2D(pool_size=(2,2)))
        model.add(Dropout(0.25))

        # model.add(Conv2D(32,(3,3),padding='same',input_shape=(width,height,depth)))
        # model.add(Activation('relu'))
        # model.add(BatchNormalization(axis=chanDim))
        model.add(Conv2D(32,(3,3),padding='same',input_shape=(width,height,depth)))
        model.add(Activation('relu'))
        model.add(BatchNormalization(axis=chanDim))
        model.add(MaxPooling2D(pool_size=(2,2)))
        model.add(Dropout(0.25))
        #FC=>RELU
        model.add(Flatten())
        model.add(Dense(128))
        model.add(Activation('relu'))
        model.add(BatchNormalization())
        model.add(Dropout(0.5))
        #use softmax to classify
        model.add(Dense(classes))
        model.add(Activation('relu'))

        return model

import matplotlib
matplotlib.use('Agg')

from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.preprocessing.image import img_to_array
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from imutils import paths
import numpy as np
import argparse
import random
import pickle
import cv2
import os

def rle_decode(mask_rle, shape=(500, 500)):
    '''
    mask_rle: run-length as string formated (start length)
    shape: (height,width) of array to return
    Returns numpy array, 1 - mask, 0 - background
    '''
    s = mask_rle.split()
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = 1
    return img.reshape(shape).T  # Needed to align to RLE direction

train_path = 'E:\BU\EC 601 product Design\miniproject2\car_data'
train_image_dir = os.path.join(train_path, 'train')
masks = pd.read_csv('C:\\Users\lliqx\PycharmProjects\miniproject2\car_train.csv')
masks['path'] = masks['0'].map(lambda x: os.path.join(train_image_dir, x))
masks.head()
imgs = os.listdir(train_path+'/train')


'''
#mask the img of train
def mask_img(file):
	img = imread(train_path + '/' + file)
	img_masks = masks.loc[masks['0'] == file, '5'].tolist()
	all_masks = np.zeros((768,768))
	for mask in img_masks:
		if mask==mask:
			all_masks += rle_decode(mask)
	return all_masks
'''


# split into training and validation groups
from sklearn.model_selection import train_test_split
masks['SUV'] = masks['5'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)
#unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()
unique_img_ids = masks.groupby('0').agg({'SUV': 'sum'}).reset_index()
unique_img_ids['has_SUV'] = unique_img_ids['SUV'].map(lambda x: 1.0 if x>0 else 0.0)
unique_img_ids['has_SUV_vec'] = unique_img_ids['has_SUV'].map(lambda x: [x])
masks.drop(['SUV'], axis=1, inplace=True)
train_ids, valid_ids = train_test_split(unique_img_ids,
                 test_size = 0.3,
                 stratify = unique_img_ids['SUV'])
train_df = pd.merge(masks, train_ids)
train_df = train_df.sample(min(15000, train_df.shape[0]))
valid_df = pd.merge(masks, valid_ids)
print(train_df.shape[0], 'training masks')
print(valid_df.shape[0], 'validation masks')


'''
img = imread(train_path + '/' + imgs[100])
fig, axarr = plt.subplots(1, 3, figsize=(15, 40))
axarr[0].axis('off')
axarr[1].axis('off')
axarr[2].axis('off')
axarr[0].imshow(img)
axarr[1].imshow(mask_img(imgs[100]))
axarr[2].imshow(img)
axarr[2].imshow(mask_img(imgs[100]), alpha=0.4)
plt.tight_layout(h_pad=0.1, w_pad=0.1)
plt.show()
'''

#  use imggenerator to process the images
dg_args = dict(featurewise_center = False,
                  samplewise_center = False,
                  rotation_range = 45,
                  width_shift_range = 0.1,
                  height_shift_range = 0.1,
                  shear_range = 0.01,
                  zoom_range = [0.9, 1.25],
                  horizontal_flip = True,
                  vertical_flip = True,
                  fill_mode = 'reflect',
                   data_format = 'channels_last')
valid_args = dict(
					fill_mode = 'reflect',
                   data_format = 'channels_last')

core_idg = ImageDataGenerator(**dg_args)
valid_idg = ImageDataGenerator(**valid_args)

def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):
    base_dir = os.path.dirname(in_df[path_col].values[0])
    print('## Ignore next message from keras, values are replaced anyways')
    df_gen = img_data_gen.flow_from_directory(base_dir,
                                     class_mode = 'sparse',
                                    **dflow_args)
    df_gen.filenames = in_df[path_col].values
    df_gen.classes = np.stack(in_df[y_col].values)
    df_gen.samples = in_df.shape[0]
    df_gen.n = in_df.shape[0]
    df_gen._set_index_array()
    df_gen.directory = '' # since we have the full path
    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))
    return df_gen

train_gen = flow_from_dataframe(core_idg, train_df,
                             path_col = 'path',
                            y_col = 'has_SUV_vec',
                            target_size = (500,500),
                             color_mode = 'rgb',
                            batch_size = 30)

# used a fixed dataset for evaluating the algorithm
valid_x, valid_y = next(flow_from_dataframe(valid_idg,
                               valid_df,
                             path_col = 'path',
                            y_col = 'has_SUV_vec',
                            target_size = (500,500),
                             color_mode = 'rgb',
                            batch_size = 1000)) # one big batch
print(valid_x.shape, valid_y.shape)

model = SmallerVGGnet.build(width=500,height=500,depth=3,classes=1)
opt = Adam(lr=0.0001, decay=0.00001)
model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['binary_accuracy'])

#train the network

model.fit_generator(train_gen, validation_data=(valid_x, valid_y), epochs=5,steps_per_epoch=5)
model.save("Car_SUV-model.h5")

